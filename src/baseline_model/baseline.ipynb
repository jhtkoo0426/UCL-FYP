{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCL COMP0029 Individual Project for Year 3 BSc\n",
    "### Robust Robotic Grasping Utilising Touch Sensing - Baseline Approach Notebook\n",
    "This notebook contains the essential code for training and testing a supervised baseline approach to grasping. Given some tactile data, end effector poses, etc., it determines whether these constraints will produce a successful/unsuccessful grasp."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set device for `PyTorch` training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two datasets have been prepared from running the \"collect sensory data\" in the Pybullet simulation. These datasets are:\n",
    "- `poses_ds.npy` that stores random 6d end effector poses generated by applying gaussian noise a manually selected base pose\n",
    "- `training_ds.npy` that stores the tactile reading data collected from the DIGIT tactile sensors in the Pybullet simulation\n",
    "\n",
    "The collected datasets are stored in `np.ndarray`s in a `.npy` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of poses_ds: (200, 6)\n",
      "Shape of training_ds: (200, 240, 320, 3)\n",
      "Shape of grasp_outcomes_ds: (200,)\n"
     ]
    }
   ],
   "source": [
    "poses_ds_file_path = \"poses_ds.npy\"\n",
    "poses_ds = np.load(poses_ds_file_path)\n",
    "print(f\"Shape of poses_ds: {poses_ds.shape}\")\n",
    "\n",
    "tactile_ds_file_path = \"training_ds.npy\"\n",
    "tactile_ds = np.load(tactile_ds_file_path)\n",
    "print(f\"Shape of training_ds: {tactile_ds.shape}\")\n",
    "\n",
    "grasp_outcomes_ds_file_path = \"grasp_outcomes.npy\"\n",
    "grasp_outcomes_ds = np.load(grasp_outcomes_ds_file_path)\n",
    "print(f\"Shape of grasp_outcomes_ds: {grasp_outcomes_ds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successes: 139 | Failures: 61\n"
     ]
    }
   ],
   "source": [
    "### Check the number of successes and failures in the dataset\n",
    "success = 0\n",
    "failure = 0\n",
    "\n",
    "for row in grasp_outcomes_ds:\n",
    "    if row == 1:\n",
    "        success += 1\n",
    "    elif row == 0:\n",
    "        failure += 1\n",
    "\n",
    "print(f\"Successes: {success} | Failures: {failure}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Approach 1 - Flattening images\n",
    "We can try to flatten the tactile data into a 1D array instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230400,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_tactile_data = [img.flatten() for img in tactile_ds]\n",
    "flattened_tactile_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 230406)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate flattened_tactile_data with poses_ds\n",
    "combined_data = np.concatenate((np.asarray(flattened_tactile_data), poses_ds), axis=1)\n",
    "combined_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train this new datast on a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approach 1 Predictions:\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n",
      "Approach 1 Accuracy: 74.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data, grasp_outcomes_ds, test_size=0.25, random_state=0)\n",
    "\n",
    "simple_lr_model = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "simple_lr_model_predictions = simple_lr_model.predict(X_test)\n",
    "\n",
    "print(f\"Approach 1 Predictions:\\n {simple_lr_model_predictions}\")\n",
    "print(f\"Approach 1 Accuracy: {np.mean(y_test == simple_lr_model_predictions)*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b1c88a32ee8050f01e0f7bb040a5164a3e1bec4536aad99aae192b94e32d990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
