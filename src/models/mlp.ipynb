{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCL COMP0029 Individual Project for Year 3 BSc\n",
    "### Robust Robotic Grasping Utilising Touch Sensing - Proposed Learning Framework Notebook\n",
    "This notebook contains the essential code for training and testing a simplified learning framework for the proposed method - a simple Gaussian process generative model that infers good hand poses from existing data on a single grasp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load packages"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 57,
=======
   "execution_count": 39,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set device for `PyTorch` training"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 58,
=======
   "execution_count": 40,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
<<<<<<< HEAD
     "execution_count": 58,
=======
     "execution_count": 40,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empty PyTorch cache"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 59,
=======
   "execution_count": 41,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load and build datasets from saved .npy files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To collect data for this experiment, you can run the \"Collect Sensory Data\" button in the Pybullet simulation. This generates a predefined number of Gaussian grasps randomly generated from a base hand pose. Each individual grasp is considered as an individual experiment, and the data collected from this experiment is split into four, each stored in its own dataset.\n",
    "\n",
    "For all object models used in this experiment, each object has 4 datasets which include:\n",
    "- `depth_ds.npy` which stores the depth tactile data from the mounted DIGIT sensors\n",
    "- `color_ds.npy` which stores the colored (RGB) version of the depth tactile data from the mounted DIGIT sensors\n",
    "- `poses_ds.npy` which stores the randomly-generated 6d hand poses from the simulation\n",
    "- `outcomes_ds.npy` which stores the outcomes of each random pose"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 60,
=======
   "execution_count": 42,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../datasets/\"\n",
    "\n",
    "object_names = ['block1', 'block2', 'block3']\n",
    "\n",
    "depth_data = np.empty((0, 2, 160, 120))\n",
    "color_data = np.empty((0, 2, 160, 120, 3))\n",
    "poses_data = np.empty((0, 6))\n",
    "grasp_outcomes_data = np.array([])\n",
    "\n",
    "\n",
    "for object_name in object_names:\n",
    "    dir = root + object_name + '_ds'\n",
    "    \n",
    "    depth_ds_file_path = dir + \"/depth_ds.npy\"\n",
    "    color_ds_file_path = dir + \"/color_ds.npy\"\n",
    "    poses_ds_file_path = dir + \"/poses_ds.npy\"\n",
    "    grasp_outcomes_ds_file_path = dir + \"/grasp_outcomes.npy\"\n",
    "\n",
    "    depth_data1 = np.load(depth_ds_file_path)\n",
    "    color_data1 = np.load(color_ds_file_path)\n",
    "    poses_data1 = np.load(poses_ds_file_path)\n",
    "    grasp_outcomes_data1 = np.load(grasp_outcomes_ds_file_path)\n",
    "\n",
    "    depth_data = np.vstack([depth_data, depth_data1])\n",
    "    color_data = np.vstack([color_data, color_data1])\n",
    "    poses_data = np.vstack([poses_data, poses_data1])\n",
    "    grasp_outcomes_data = np.concatenate([grasp_outcomes_data, grasp_outcomes_data1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These datasets should all be in the form of $(N\\times...)$ where $N$ is the number of examples:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 61,
=======
   "execution_count": 43,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Shape of depth_ds: (340, 2, 160, 120)\n",
      "Shape of color_ds: (340, 2, 160, 120, 3)\n",
      "Shape of poses_ds: (340, 6)\n",
      "Shape of grasp_outcomes_ds: (340,)\n"
=======
      "Shape of depth_data: (800, 2, 160, 120)\n",
      "Shape of color_data: (800, 2, 160, 120, 3)\n",
      "Shape of poses_data: (800, 6)\n",
      "Shape of grasp_outcomes_data: (800,)\n"
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
     ]
    }
   ],
   "source": [
    "print(f\"Shape of depth_ds: {depth_data.shape}\")\n",
    "print(f\"Shape of color_ds: {color_data.shape}\")\n",
    "print(f\"Shape of poses_ds: {poses_data.shape}\")\n",
    "print(f\"Shape of grasp_outcomes_ds: {grasp_outcomes_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we confirm the number of successful and unsuccessful grasps recorded. This helps us in the next section to determine how many examples we should include for each class in order to produce a balanced dataset."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 62,
=======
   "execution_count": 44,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "# of sucessesful grasps: 170\n",
      "# of unsuccessful grasps: 170\n"
=======
      "# of sucessesful grasps: 400\n",
      "# of unsuccessful grasps: 400\n"
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
     ]
    }
   ],
   "source": [
    "print(f\"# of sucessesful grasps: {(grasp_outcomes_data == 1).sum()}\")\n",
    "print(f\"# of unsuccessful grasps: {(grasp_outcomes_data == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a. Sampling\n",
    "We sample a pre-defined number of examples from each class label (successful and unsuccessful grasps) to reduce the computational cost."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 63,
=======
   "execution_count": 45,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 400"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 64,
=======
   "execution_count": 46,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample n samples from the datasets\n",
    "def sample_data(depth_data, color_data, poses_data, outcomes_data, no_of_examples):\n",
    "    d, c, p, o = [], [], [], []\n",
    "    for label in np.unique(outcomes_data):\n",
    "        indices = np.where(outcomes_data == label)[0]\n",
    "\n",
    "        for i in range(no_of_examples):\n",
    "           # if np.mean(depth_data[indices[i]]) > 1e-7 and np.mean(color_data[indices[i]]) > 1e-7:\n",
    "            d.append(depth_data[indices[i]])\n",
    "            c.append(color_data[indices[i]])\n",
    "            p.append(poses_data[indices[i]])\n",
    "            o.append(outcomes_data[indices[i]])\n",
    "    \n",
    "    depth_data = torch.from_numpy(np.array(d))\n",
    "    color_data = torch.from_numpy(np.array(c))\n",
    "    poses_data = torch.from_numpy(np.array(p))\n",
    "    outcomes_data = torch.from_numpy(np.array(o))\n",
    "    return depth_data, color_data, poses_data, outcomes_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sample `sample_size` samples:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 65,
=======
   "execution_count": 47,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_data, color_data, poses_data, grasp_outcomes_data = sample_data(depth_data, color_data, poses_data, grasp_outcomes_data, no_of_examples=sample_size)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 66,
=======
   "execution_count": 48,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of depth_data: torch.Size([800, 2, 160, 120])\n",
      "Shape of color_data: torch.Size([800, 2, 160, 120, 3])\n",
      "Shape of poses_data: torch.Size([800, 6])\n",
      "Shape of grasp_outcomes_data: torch.Size([800])\n",
      "# of sucessesful grasps: 400\n",
      "# of unsuccessful grasps: 400\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of depth_data: {depth_data.shape}\")\n",
    "print(f\"Shape of color_data: {color_data.shape}\")\n",
    "print(f\"Shape of poses_data: {poses_data.shape}\")\n",
    "print(f\"Shape of grasp_outcomes_data: {grasp_outcomes_data.shape}\")\n",
    "print(f\"# of sucessesful grasps: {(grasp_outcomes_data == 1).sum()}\")\n",
    "print(f\"# of unsuccessful grasps: {(grasp_outcomes_data == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 67,
=======
   "execution_count": 49,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tensor):\n",
    "    # Normalize & standardize each column\n",
    "    mean = torch.mean(tensor, axis=0)\n",
    "    std = torch.std(tensor, axis=0)\n",
    "    tensor = (tensor - mean) / std\n",
    "    tensor[torch.isnan(tensor)] = 0\n",
    "    tensor[torch.isinf(tensor)] = 0\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def downsample_2d_tensor(tensor, factor=2):\n",
    "    return torch.nn.functional.avg_pool2d(tensor.unsqueeze(0), kernel_size=factor, stride=factor, padding=0).squeeze(0)\n",
    "\n",
    "\n",
    "def downsample_3d_tensor(tensor, factor=2):\n",
    "    pooling_kernel = 2\n",
    "    pooling_layer = torch.nn.AvgPool2d(kernel_size=pooling_kernel, stride=pooling_kernel)\n",
    "    downsampled_tensor = pooling_layer(tensor.permute(0, 3, 1, 2))\n",
    "    downsampled_tensor = downsampled_tensor.permute(0, 2, 3, 1)\n",
    "    \n",
    "    return downsampled_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a tactile+visual data representation with CNNs as the input for our MLP approach. We concatenate the depth and color to get our tactile dataset, then concatenate the tactile and visual datasets together."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 68,
=======
   "execution_count": 50,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of depth_data: torch.Size([800, 160, 240])\n",
      "Shape of color_data: torch.Size([800, 160, 240, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "tensor([[ 0.4110,  0.4594,  0.2730,  1.5336,  0.9927,  0.5848],\n",
       "        [ 0.4147,  0.1815, -0.0686,  1.5451,  0.9559,  0.5868],\n",
       "        [ 0.5218,  0.1307,  0.3476,  1.5524,  0.9544,  0.6057],\n",
       "        ...,\n",
       "        [ 0.1071,  0.4600,  0.8730,  0.1263,  0.9902, -0.9222],\n",
       "        [ 0.2748,  0.4403,  0.7549,  0.1452,  1.0301, -0.9142],\n",
       "        [ 0.4833,  0.3056,  0.9878,  0.1515,  1.0042, -0.9271]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 68,
=======
       "tensor([[ 1.4218,  0.8917,  1.1777, -1.6748, -0.2755, -0.3376],\n",
       "        [-0.4224, -0.0056,  1.0018,  0.7977,  1.1299, -0.3832],\n",
       "        [ 0.1029,  1.2736, -0.4137, -1.1278,  0.9966, -2.0037],\n",
       "        ...,\n",
       "        [ 1.3582,  0.6914, -1.1187, -1.0040, -0.9741, -0.0867],\n",
       "        [-0.9646, -0.4349, -0.4510,  0.7650,  0.7262,  1.9305],\n",
       "        [ 2.2390,  1.4417, -2.1154,  0.2150,  0.2415,  0.6169]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 50,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_data = torch.cat([depth_data[:, 0, :, :], depth_data[:, 1, :, :]], dim=2)\n",
    "color_data = torch.cat([color_data[:, 0, :, :, :], color_data[:, 1, :, :, :]], dim=2)\n",
    "print(f\"Shape of depth_data: {depth_data.shape}\")\n",
    "print(f\"Shape of color_data: {color_data.shape}\")\n",
    "\n",
    "depth_ds = normalize(depth_data)\n",
    "color_ds = normalize(color_data)\n",
    "visual_ds = torch.from_numpy(np.nan_to_num(normalize(poses_data)))\n",
    "visual_ds"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 69,
=======
   "execution_count": 51,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 153606])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 69,
=======
     "execution_count": 51,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tactile_ds = torch.cat([depth_ds, color_ds], dim=1)\n",
    "# complete_ds = torch.cat([tactile_ds, visual_ds], dim=1)\n",
    "tactile_ds = torch.cat([depth_ds.unsqueeze(-1), color_ds], dim=-1)\n",
    "tactile_ds = torch.nan_to_num(tactile_ds)\n",
    "complete_ds = torch.cat([tactile_ds.reshape(tactile_ds.shape[0], -1), visual_ds], dim=1)\n",
    "complete_ds = torch.nan_to_num(complete_ds)\n",
    "complete_ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use the `complete_ds` for this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3c. CNN dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 70,
=======
   "execution_count": 52,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple convolutional neural network that extracts features from an input tensor\n",
    "class FeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 71,
=======
   "execution_count": 53,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 512])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 71,
=======
     "execution_count": 53,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess data using CNN feature extraction\n",
    "cnn = FeatureExtractorCNN()\n",
    "cnn_tactile = torch.cat([cnn(img.float().permute(2,0,1)).unsqueeze(0) for img in tactile_ds])\n",
    "cnn_tactile = cnn_tactile.reshape(cnn_tactile.shape[0], -1)\n",
    "cnn_tactile.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our data into training and testing datasets for future sections."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 72,
=======
   "execution_count": 54,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 518])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 72,
=======
     "execution_count": 54,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We simply combine the cnn-processed tactile data (from Section 5.3.1) with the visual data\n",
    "cnn_complete_ds = torch.cat([cnn_tactile.reshape(cnn_tactile.shape[0], -1), visual_ds], dim=1)\n",
    "cnn_complete_ds.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 73,
=======
   "execution_count": 55,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cnn_complete_train, X_cnn_complete_test, y_cnn_complete_train, y_cnn_complete_test = train_test_split(cnn_complete_ds.detach().numpy(), grasp_outcomes_data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our MLP model, there are two fully connected (dense) layers, each with an activation function (ReLU for the first layer and no activation for the second layer). The input size, hidden size, and output size are parameters that need to be specified when creating an instance of the MLP."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 74,
=======
   "execution_count": 56,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of our MLP with the desired input size and output size"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 75,
=======
   "execution_count": 57,
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP model: 91.88%\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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",
=======
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGiCAYAAADp4c+XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlcklEQVR4nO3de3RU9bn/8U+CyZASMpAQJgkYjIINXrg0aBjFCzQaqeWARBSLbRT6o9aYCiNF05+AWHSUniMWuVUPgtZyVKwg9FQoxhq1DQGiWK8IBQ0KM4iSRFIziZn5/eE5084mSgZ2MvPb+/3q2msle+/57idrVR+f5/v97kkIhUIhAQAA20iMdQAAAKBrkfwBALAZkj8AADZD8gcAwGZI/gAA2AzJHwAAmyH5AwBgMyR/AABshuQPAIDNkPwBALAZkj8AAHGira1Nc+bMUV5enlJSUnTGGWfol7/8pf71TfyhUEhz585Vdna2UlJSVFRUpN27d0f1HJI/AABx4v7779fy5cu1ZMkSvfvuu7r//vu1cOFCPfTQQ+F7Fi5cqMWLF2vFihWqqalRjx49VFxcrObm5g4/J4Ev9gEAID58//vfl8vl0sqVK8PnSkpKlJKSoieeeEKhUEg5OTm67bbbNGvWLElSQ0ODXC6XVq9ercmTJ3foOVT+AAB0okAgoMbGxogjEAi0e+8FF1ygyspKvf/++5KkN954Q6+++qrGjh0rSdq3b598Pp+KiorCn3E6nSosLFR1dXWHYzrlJP4eAAAsqfXwXtPG8i55XPPnz484N2/ePN11113H3HvHHXeosbFR+fn56tatm9ra2nTPPfdoypQpkiSfzydJcrlcEZ9zuVzhax1B8gcAwCjYZtpQFRUV8ng8EeccDke79z799NP63e9+pzVr1ujss8/Wzp07NWPGDOXk5Ki0tNS0mOIu+X/x1Pzj3wTYQMq188I/n5LcL4aRAPHly5aPYx1CVBwOx9cme6Of//znuuOOO8Jz9+eee64+/PBDeb1elZaWKisrS5Lk9/uVnZ0d/pzf79ewYcM6HBNz/gAAGIWC5h1R+Mc//qHExMjU3K1bNwWDX42Tl5enrKwsVVZWhq83NjaqpqZGbre7w8+Ju8ofAICYC0aXtM0ybtw43XPPPcrNzdXZZ5+t119/XQ888ICmTp0qSUpISNCMGTO0YMECDRo0SHl5eZozZ45ycnI0YcKEDj+H5A8AgEEoyordLA899JDmzJmjm2++WYcOHVJOTo5+8pOfaO7cueF7Zs+eraamJk2fPl319fUaNWqUNm3apO7du3f4OXG3z585f+ArzPkD7euKOf+WA2+bNlZyztmmjWUWKn8AAIxi1PbvKiR/AACMYtT27yqs9gcAwGao/AEAMDLxJT/xiOQPAIARbX8AAGAlVP4AABix2h8AAHuJ1Ut+ugptfwAAbIbKHwAAI9r+AADYjMXb/iR/AACMLL7Pnzl/AABshsofAAAj2v4AANiMxRf80fYHAMBmqPwBADCi7Q8AgM3Q9gcAAFZC5Q8AgEEoZO19/iR/AACMLD7nT9sfAACbofIHAMDI4gv+SP4AABhZvO1P8gcAwIgv9gEAAFZC5Q8AgBFtfwAAbMbiC/5o+wMAYDNU/gAAGNH2BwDAZmj7AwAAK6HyBwDAyOKVP8kfAAADq3+rH21/AABshsofAAAj2v4AANgMW/0AALAZi1f+zPkDABAnTjvtNCUkJBxzlJWVSZKam5tVVlamjIwMpaamqqSkRH6/P+rnkPwBADAKBc07orB9+3YdPHgwfGzZskWSNGnSJEnSzJkztXHjRq1du1ZVVVU6cOCAJk6cGPWfR9sfAACjGLX9MzMzI36/7777dMYZZ+iSSy5RQ0ODVq5cqTVr1mjMmDGSpFWrVmnw4MHaunWrRo4c2eHnUPkDANCJAoGAGhsbI45AIHDcz7W0tOiJJ57Q1KlTlZCQoNraWrW2tqqoqCh8T35+vnJzc1VdXR1VTCR/AACMTGz7e71eOZ3OiMPr9R43hPXr16u+vl433HCDJMnn8yk5OVm9evWKuM/lcsnn80X159H2BwDAyMS2f0VFhTweT8Q5h8Nx3M+tXLlSY8eOVU5Ojmmx/C+SPwAAncjhcHQo2f+rDz/8UC+88IKeffbZ8LmsrCy1tLSovr4+ovr3+/3KysqKanza/gAAGAWD5h0nYNWqVerbt6+uvPLK8LmCggIlJSWpsrIyfG7Xrl2qq6uT2+2OanwqfwAAjGL4hr9gMKhVq1aptLRUp5zyzzTtdDo1bdo0eTwepaenKy0tTeXl5XK73VGt9JdI/gAAxJUXXnhBdXV1mjp16jHXFi1apMTERJWUlCgQCKi4uFjLli2L+hkkfwAAjGL4et/LL79coVCo3Wvdu3fX0qVLtXTp0pN6BskfAAAjvtgHAACb4Yt9AACAlVD5AwBgRNsfAACboe0PAACshMofAAAji1f+JH8AAIy+Zp+9VdD2BwDAZqj8AQAwou0PAIDNWDz50/YHAMBmqPwBADDiJT8AANiMxdv+JH8AAIzY6gcAAKyEyh8AACPa/gAA2IzFkz9tfwAAbIbKHwAAI7b6AQBgL6Egq/0BAICFUPkDAGBk8QV/JH8AAIwsPudP2x8AAJuh8gcAwMjiC/5I/gAAGDHnDwCAzVg8+TPnDwCAzVD5AwBgZPGv9CX5AwBgZPG2P8nfpvyN/9Cv/7RTf9l9QM2tbTo1PVXzrxqps/tlSJKGzV3T7udmXD5MN4w6qytDBWJm7hyP5s65LeLce7v26JxzL4lRRIA5SP421PhFi274zy06L8+lJT+8VOk9uuvDTz9XWkpy+J4Xfn5VxGde3X1A85+rUdFZuV0dLhBTb739noqvmBz+/csvv4xhNOgybPWD1ax65R1lpX1Ld181MnyuX+/UiHv69EyJ+P2l9z7Weae51D898j7A6r78sk1+/yexDgNdzeJv+Is6+R8+fFiPPvqoqqur5fP5JElZWVm64IILdMMNNygzM9P0IGGuql0fyT0wW7OeekW1HxxS357f0jXnD1LJiIHt3v/p0S/06vsf6+6J7i6OFIi9QQPzVPdBrZqbA9paU6v/e6dX+/cfiHVYwEmJaqvf9u3bdeaZZ2rx4sVyOp26+OKLdfHFF8vpdGrx4sXKz8/Xjh07jjtOIBBQY2NjxBEIBE74j0B0PjpyVGu371Zuek8t/9FoTTp/kBb+sVYbXt/b7v0bXt+nbzmS9N3Bp3ZxpEBsbdv2uqb+eKauHHe9bimvUN5puXrpxXVKTe0R69DQ2YIh8444FFXlX15erkmTJmnFihVKSEiIuBYKhXTTTTepvLxc1dXV3ziO1+vV/PnzI87NmzdPd911VzTh4AQFQ9JZOen62WXDJEn52en6u79ez2zfrX8bfvox9z/3+l59b8hpciR16+JIgdjatPnP4Z/ffPNd1Wx7XXv31GjS1eO0avWTMYwMnS3Eav9/euONN7R69epjEr8kJSQkaObMmRo+fPhxx6moqJDH44k453A4ogkFJyEztbvOyHRGnMvLdOqFd/Yfc+9rHxzSB4cbdf81F3ZVeEDcamho1Pu792rgwNNiHQpwUqJq+2dlZWnbtm1fe33btm1yuVzHHcfhcCgtLS3iIPl3naG5mfrgcGPEuQ8/bVR2r2Nbmete+7vOyknXt7N6d1V4QNzq0eNbOuP0ATp48FCsQ0Fns3jbP6rkP2vWLE2fPl233nqrNmzYoJqaGtXU1GjDhg269dZbddNNN2n27NmdFStMcv0F+Xrzo8P6z6q3Vffp5/rj3z7Q73fs0bXnD4q472hzq7a8XaerCs6IUaRAbC28b44uvmikBgzoL/fIEfr92pVqawvqyafWxzo0dLZQ0LwjSh9//LGuv/56ZWRkKCUlReeee27EerpQKKS5c+cqOztbKSkpKioq0u7du6N6RlRt/7KyMvXp00eLFi3SsmXL1NbWJknq1q2bCgoKtHr1al1zzTVRBYCud06/DD1w3cVavGWnHq56U/16pernYwt05dC8iPs2vfWhJOmKcwfEIkwg5vr1z9YTv12qjIze+uSTz/SXv27ThReN0+HDn8U6NHS2GFXsR44c0YUXXqjRo0fr+eefV2Zmpnbv3q3evf/ZfV24cKEWL16sxx57THl5eZozZ46Ki4v1zjvvqHv37h16TkIodGIvMG5tbdXhw4clSX369FFSUtKJDHOML56af/ybABtIuXZe+OdTkvvFMBIgvnzZ8nGnP6Pp7immjXXK7Y8es6PN4XC0O919xx136C9/+YteeeWVdscKhULKycnRbbfdplmzZkmSGhoa5HK5tHr1ak2ePLndzxmd8Lf6JSUlKTs7W9nZ2aYlfgAA4kIwaNrh9XrldDojDq/X2+5jN2zYoBEjRmjSpEnq27evhg8frkceeSR8fd++ffL5fCoqKgqfczqdKiwsPO5Ou3/FV/oCAGBk4oK/iooKNTQ0RBwVFRXtPnbv3r1avny5Bg0apM2bN+unP/2pfvazn+mxxx6TpPDL9YyL610uV/haR/B6XwAAOtHXtfjbEwwGNWLECN17772SpOHDh+utt97SihUrVFpaalpMVP4AABjFaLV/dna2zjor8ptTBw8erLq6OklfbbmXJL/fH3GP3+8PX+sIkj8AAEYx2ud/4YUXateuXRHn3n//fQ0Y8NWuq7y8PGVlZamysjJ8vbGxUTU1NXK7O/79K7T9AQCIEzNnztQFF1yge++9V9dcc422bdumhx9+WA8//LCkr96mO2PGDC1YsECDBg0Kb/XLycnRhAkTOvwckj8AAAaxerf/eeedp3Xr1qmiokJ333238vLy9OCDD2rKlH9uPZw9e7aampo0ffp01dfXa9SoUdq0aVOH9/hLJ7HPv7Owzx/4Cvv8gfZ1xT7/o7dPNG2s1PufNW0sszDnDwCAzdD2BwDAKE6/kMcsJH8AAIxO4At5/n9C8gcAwMjilT9z/gAA2AyVPwAABiGLV/4kfwAAjCye/Gn7AwBgM1T+AAAYxegNf12F5A8AgBFtfwAAYCVU/gAAGFm88if5AwBgEGffeWc62v4AANgMlT8AAEa0/QEAsBmSPwAA9mL11/sy5w8AgM1Q+QMAYGTxyp/kDwCAkbXf7kvbHwAAu6HyBwDAwOoL/kj+AAAYWTz50/YHAMBmqPwBADCy+II/kj8AAAZWn/On7Q8AgM1Q+QMAYETbHwAAe7F625/kDwCAkcUrf+b8AQCwGSp/AAAMQhav/En+AAAYWTz50/YHAMBmqPwBADCg7Q8AgN1YPPnT9gcAwGao/AEAMLB625/KHwAAg1DQvCMad911lxISEiKO/Pz88PXm5maVlZUpIyNDqampKikpkd/vj/rvI/kDAGAQq+QvSWeffbYOHjwYPl599dXwtZkzZ2rjxo1au3atqqqqdODAAU2cODHqZ9D2BwAgjpxyyinKyso65nxDQ4NWrlypNWvWaMyYMZKkVatWafDgwdq6datGjhzZ4WdQ+QMAYBRKMO0IBAJqbGyMOAKBwNc+evfu3crJydHpp5+uKVOmqK6uTpJUW1ur1tZWFRUVhe/Nz89Xbm6uqquro/rzSP4AABiY2fb3er1yOp0Rh9frbfe5hYWFWr16tTZt2qTly5dr3759uuiii/T555/L5/MpOTlZvXr1iviMy+WSz+eL6u+j7Q8AQCeqqKiQx+OJOOdwONq9d+zYseGfhwwZosLCQg0YMEBPP/20UlJSTIuJ5A8AgEEomGDaWA6H42uT/fH06tVLZ555pvbs2aPLLrtMLS0tqq+vj6j+/X5/u2sEvgltfwAADGK52v9fHT16VH//+9+VnZ2tgoICJSUlqbKyMnx9165dqqurk9vtjmpcKn8AAOLErFmzNG7cOA0YMEAHDhzQvHnz1K1bN1133XVyOp2aNm2aPB6P0tPTlZaWpvLycrnd7qhW+kskfwAAjhEKmdf2j8ZHH32k6667Tp9++qkyMzM1atQobd26VZmZmZKkRYsWKTExUSUlJQoEAiouLtayZcuifk5CKBQKmR38yfjiqfmxDgGICynXzgv/fEpyvxhGAsSXL1s+7vRnfFQ4xrSx+te8aNpYZmHOHwAAm6HtDwCAgZmr/eMRyR8AAIP4mhA3H8kfAAADq1f+zPkDAGAzVP4AABhYvfIn+QMAYGD1OX/a/gAA2AyVPwAABrT9AQCwmVi93rer0PYHAMBmqPwBADA42a/ijXckfwAADIK0/QEAgJVQ+QMAYGD1BX8kfwAADNjqBwCAzfCGPwAAYClU/gAAGND2BwDAZtjqBwAALIXKHwAAA7b6AQBgM6z2BwAAlkLlDwCAgdUX/JH8AQAwsPqcP21/AABshsofAAADqy/4i7vkn3LtvFiHAMSdL1s+jnUIgK0w5w8AgM0w5w8AACwl7ir/3qkDYx0CEBeOHN0T/rn18N4YRgLEl6Q+p3f6M2j7AwBgMxZf70fbHwAAu6HyBwDAgLY/AAA2w2p/AABgKVT+AAAYBGMdQCej8gcAwCCkBNOOE3XfffcpISFBM2bMCJ9rbm5WWVmZMjIylJqaqpKSEvn9/qjHJvkDABBntm/frt/85jcaMmRIxPmZM2dq48aNWrt2raqqqnTgwAFNnDgx6vFJ/gAAGARD5h3ROnr0qKZMmaJHHnlEvXv3Dp9vaGjQypUr9cADD2jMmDEqKCjQqlWr9Ne//lVbt26N6hkkfwAADIJKMO0IBAJqbGyMOAKBwNc+u6ysTFdeeaWKiooiztfW1qq1tTXifH5+vnJzc1VdXR3V30fyBwDAwMw5f6/XK6fTGXF4vd52n/vkk0/qtddea/e6z+dTcnKyevXqFXHe5XLJ5/NF9fex2h8AgE5UUVEhj8cTcc7hcBxz3/79+3Xrrbdqy5Yt6t69e6fGRPIHAMDAzK1+Doej3WRvVFtbq0OHDuk73/lO+FxbW5tefvllLVmyRJs3b1ZLS4vq6+sjqn+/36+srKyoYiL5AwBgcDJb9E7Ud7/7Xb355psR52688Ubl5+fr9ttv16mnnqqkpCRVVlaqpKREkrRr1y7V1dXJ7XZH9SySPwAAcaBnz54655xzIs716NFDGRkZ4fPTpk2Tx+NRenq60tLSVF5eLrfbrZEjR0b1LJI/AAAG8fqGv0WLFikxMVElJSUKBAIqLi7WsmXLoh4nIRQKxdXXFvdOHRjrEIC4cOTonvDPrYf3xjASIL4k9Tm905/xR9dk08b6nv9J08YyC1v9AACwGdr+AAAYxGLBX1ci+QMAYBC0du6n7Q8AgN1Q+QMAYBCk7Q8AgL3E1Ta4TkDyBwDAIF73+ZuFOX8AAGyGyh8AAINgAnP+AADYitXn/Gn7AwBgM1T+AAAYWH3BH8kfAAAD3vAHAAAshcofAAAD3vAHAIDNsNofAABYCpU/AAAGVl/wR/IHAMCArX4AANgMc/4AAMBSqPwBADBgzh8AAJux+pw/bX8AAGyGyh8AAAOrV/4kfwAADEIWn/On7Q8AgM1Q+QMAYEDbHwAAm7F68qftDwCAzVD5AwBgYPXX+5L8AQAw4A1/AADYDHP+AADAUqj8AQAwsHrlT/IHAMDA6gv+aPsDAGAzVP4AABhYfbU/lT8AAAZBE49oLF++XEOGDFFaWprS0tLkdrv1/PPPh683NzerrKxMGRkZSk1NVUlJifx+f9R/H8kfAIA40b9/f913332qra3Vjh07NGbMGI0fP15vv/22JGnmzJnauHGj1q5dq6qqKh04cEATJ06M+jkJoVAortY19E4dGOsQgLhw5Oie8M+th/fGMBIgviT1Ob3Tn+EdcL1pY1V8+MRJfT49PV2/+tWvdPXVVyszM1Nr1qzR1VdfLUl67733NHjwYFVXV2vkyJEdHpM5fwAADIImrvcPBAIKBAIR5xwOhxwOxzd+rq2tTWvXrlVTU5Pcbrdqa2vV2tqqoqKi8D35+fnKzc2NOvnT9gcAoBN5vV45nc6Iw+v1fu39b775plJTU+VwOHTTTTdp3bp1Ouuss+Tz+ZScnKxevXpF3O9yueTz+aKKicofAAADM1/yU1FRIY/HE3Hum6r+b3/729q5c6caGhr0zDPPqLS0VFVVVSZGRPIHAOAYZi6G60iL/18lJydr4MCv1r8VFBRo+/bt+vWvf61rr71WLS0tqq+vj6j+/X6/srKyooqJtj8AAAax2urXbizBoAKBgAoKCpSUlKTKysrwtV27dqmurk5utzuqMan8AQCIExUVFRo7dqxyc3P1+eefa82aNXrppZe0efNmOZ1OTZs2TR6PR+np6UpLS1N5ebncbndUi/0kkj8AAMeI1Rv+Dh06pB/96Ec6ePCgnE6nhgwZos2bN+uyyy6TJC1atEiJiYkqKSlRIBBQcXGxli1bFvVz2OcPxCn2+QPt64p9/nee9gPTxlrwwRrTxjILc/4AANgMbX8AAAziqiXeCUj+AAAYmLnPPx7R9gcAwGao/AEAMDDz3f7xiOQPAICBtVM/bX8AAGyHyh8AAAOrL/gj+QMAYMCcPwAANmPt1M+cPwAAtkPlDwCAAXP+AADYTMjijX/a/gAA2AyVPwAABrT9AQCwGatv9aPtDwCAzVD5AwBgYO26n+QPAMAxaPvD8hITE/WLOTO0860/68Anb+m1v72oWbeXxTosoMu1tbXpoYcfV/HVN6hg9HhdMelGrVi1RqHQPxNBKBTSkkce16X/9gMVjB6vH99aoQ/3fxzDqIHoUflDMzw/0dQf/0A3T5+td9/dreHfOVdLlt+nxsbP9fDyx2MdHtBlVj6xVk+t/2/dc+dtGpg3QG+/977uvGeRUlN76PpJ4yVJj/5urX73zAbdc+dt6pedpSWPPK6feO7Uc0/8Rg5Hcoz/ApiF1f6wvPMLh+uPf6jUnza/JEnaX/exSiZ9XwUFQ2MbGNDFdr71rkZfNFKXXHC+JKlftkt/3FKlN9/ZJemrqv+3T6/X9NLJGnORW5J075xZumTcdap85a/6XtGlsQodJuMlP7C8bTWv65JL3Tpj4GmSpHPOyddI9wi98Keq2AYGdLFh5wxWzY6d+qDuI0nSe7v36rW/va2LRo6QJH10wKfDnx6Re8Tw8Gd6pvbQkLO+rTfeei8mMaNzBE084pHplf/+/fs1b948Pfroo197TyAQUCAQiDjncDjkcDjMDgcdsOg/Vqhnz1Rte+1PamtrU7du3bRg/gNa+/SGWIcGdKkf//AaNf3jHxr3g+nqlpiotmBQP5tequ8Xj5EkHf7siCQpI713xOcy0nvr8KdHujxe4ESZXvl/9tlneuyxx77xHq/XK6fTGXF4vV6zQ0EHXVXyPU269t/0f6bO1KWjxuvm6bN1y8+mafIProp1aECX2vTiy/rDn/6s+++aradXPaR77rxNq//r93ruj1tiHRq6WMjE/8WjqCv/DRu+uRrcu3fvcceoqKiQx+OJOEfVHzt3L7hDDz7wGz37zH9Lkt55+331z83RzFk36ck162IcHdB1/mPpSv34+mvCc/dnnpGng75D+s/fPq3x37tMff6n4v/0syPK7JMe/tynnx3RtwedEYuQ0UnitV1vlqiT/4QJE5SQkBCx9cUoISHhG8egxR9fUlK6KxiM/L96sC2oxASWhMBempsDSkiM/PdXYmKigv/z77v+OVnqk9FbW2t3Kv/Mr5L90aYm/e2dXbrmqiu7PF7gREWd/LOzs7Vs2TKNHz++3es7d+5UQUHBSQeGrrPp+Rfl+fnN+mj/Ab377m4NGXqWbi6fqt89vjbWoQFd6tILC/XIY08q29VXA/MG6N339+jxp57VVVdeLumrwuaH10zQw489qQH9+6lfjktLHvmt+vbJ0HcvuiDG0cNMwW8ocK0g6uRfUFCg2trar03+x+sKIP7cPutu/WLODP37ovnqk5kh38FDWv3of2mhd0msQwO61C9m/lQPPfK4Fvz7Un12pF6ZfdI1afz39NMbfxC+Z+qUSfrii2bdtXCxPj96VN8ZcrZW/Mcv2eNvMVbPYgmhKDP1K6+8oqamJl1xxRXtXm9qatKOHTt0ySWXnFBAvVMHntDnAKs5cnRP+OfWw8dfSwPYRVKf0zv9GdcPmGjaWE98+KxpY5kl6sr/oosu+sbrPXr0OOHEDwBAPLD6u/15wx8AAAbxukXPLCznBgDAZqj8AQAwYJ8/AAA2w5w/AAA2w5w/AACwFCp/AAAMmPMHAMBmrP6mWtr+AADECa/Xq/POO089e/ZU3759NWHCBO3atSvinubmZpWVlSkjI0OpqakqKSmR3++P6jkkfwAADIIKmXZEo6qqSmVlZdq6dau2bNmi1tZWXX755WpqagrfM3PmTG3cuFFr165VVVWVDhw4oIkTo3sdcdTv9u9svNsf+Arv9gfa1xXv9h+X+33Txnpm9+8VCAQiznX0q+0/+eQT9e3bV1VVVbr44ovV0NCgzMxMrVmzRldffbUk6b333tPgwYNVXV2tkSNHdigmKn8AADqR1+uV0+mMOLxeb4c+29DQIElKT0+XJNXW1qq1tVVFRUXhe/Lz85Wbm6vq6uoOx8SCPwAADMzc519RUSGPxxNxriNVfzAY1IwZM3ThhRfqnHPOkST5fD4lJyerV69eEfe6XC75fL4Ox0TyBwDAwMw3/HW0xW9UVlamt956S6+++qppsfwv2v4AAMSZW265RX/4wx/05z//Wf379w+fz8rKUktLi+rr6yPu9/v9ysrK6vD4JH8AAAxCoZBpR7TPveWWW7Ru3Tq9+OKLysvLi7heUFCgpKQkVVZWhs/t2rVLdXV1crvdHX4ObX8AAAxi9Ya/srIyrVmzRs8995x69uwZnsd3Op1KSUmR0+nUtGnT5PF4lJ6errS0NJWXl8vtdnd4pb9E8gcA4Bix+mKf5cuXS5IuvfTSiPOrVq3SDTfcIElatGiREhMTVVJSokAgoOLiYi1btiyq57DPH4hT7PMH2tcV+/wvP/UK08b60/5Npo1lFip/AAAMzFztH49I/gAAGMRZU9x0rPYHAMBmqPwBADCg7Q8AgM3EarV/V6HtDwCAzVD5AwBgELT4gj+SPwAABtZO/bT9AQCwHSp/AAAMWO0PAIDNkPwBALAZ3vAHAAAshcofAAAD2v4AANgMb/gDAACWQuUPAICB1Rf8kfwBADCw+pw/bX8AAGyGyh8AAAPa/gAA2AxtfwAAYClU/gAAGFh9nz/JHwAAgyBz/gAA2IvVK3/m/AEAsBkqfwAADGj7AwBgM7T9AQCApVD5AwBgQNsfAACboe0PAAAshcofAAAD2v4AANgMbX8AAGApVP4AABiEQsFYh9CpSP4AABgELd72J/kDAGAQsviCP+b8AQCIEy+//LLGjRunnJwcJSQkaP369RHXQ6GQ5s6dq+zsbKWkpKioqEi7d++O+jkkfwAADIIKmXZEo6mpSUOHDtXSpUvbvb5w4UItXrxYK1asUE1NjXr06KHi4mI1NzdH9Rza/gAAGMSq7T927FiNHTu23WuhUEgPPvig7rzzTo0fP16S9Pjjj8vlcmn9+vWaPHlyh59D5Q8AQCcKBAJqbGyMOAKBQNTj7Nu3Tz6fT0VFReFzTqdThYWFqq6ujmoskj8AAAbBUMi0w+v1yul0RhxerzfqmHw+nyTJ5XJFnHe5XOFrHUXbHwAAAzPf8FdRUSGPxxNxzuFwmDb+iSD5AwDQiRwOhynJPisrS5Lk9/uVnZ0dPu/3+zVs2LCoxqLtDwCAQSgUMu0wS15enrKyslRZWRk+19jYqJqaGrnd7qjGovIHAMAgVm/4O3r0qPbs2RP+fd++fdq5c6fS09OVm5urGTNmaMGCBRo0aJDy8vI0Z84c5eTkaMKECVE9h+QPAECc2LFjh0aPHh3+/X/XCpSWlmr16tWaPXu2mpqaNH36dNXX12vUqFHatGmTunfvHtVzEkJx9g7D3qkDYx0CEBeOHP3nf/23Ht4bw0iA+JLU5/ROf0aftDNNG+tw4/umjWUWKn8AAAyC8VUXm47kDwCAQZw1xU3Han8AAGyGyh8AAINYrfbvKiR/AAAMaPsDAABLofIHAMCA1f4AANiMmV/sE49o+wMAYDNU/gAAGND2BwDAZljtDwAALIXKHwAAA6sv+CP5AwBgYPW2P8kfAAADqyd/5vwBALCZhJDV//MGAIAonZLcz7Sxvmz52LSxzELyR4RAICCv16uKigo5HI5YhwPEBf65gNWQ/BGhsbFRTqdTDQ0NSktLi3U4QFzgnwtYDXP+AADYDMkfAACbIfkDAGAzJH9EcDgcmjdvHouagH/BPxewGhb8AQBgM1T+AADYDMkfAACbIfkDAGAzJH8AAGyG5A8AgM2Q/BG2dOlSnXbaaerevbsKCwu1bdu2WIcExNTLL7+scePGKScnRwkJCVq/fn2sQwJMQfKHJOmpp56Sx+PRvHnz9Nprr2no0KEqLi7WoUOHYh0aEDNNTU0aOnSoli5dGutQAFOxzx+SpMLCQp133nlasmSJJCkYDOrUU09VeXm57rjjjhhHB8ReQkKC1q1bpwkTJsQ6FOCkUflDLS0tqq2tVVFRUfhcYmKiioqKVF1dHcPIAACdgeQPHT58WG1tbXK5XBHnXS6XfD5fjKICAHQWkj8AADZD8of69Omjbt26ye/3R5z3+/3KysqKUVQAgM5C8oeSk5NVUFCgysrK8LlgMKjKykq53e4YRgYA6AynxDoAxAePx6PS0lKNGDFC559/vh588EE1NTXpxhtvjHVoQMwcPXpUe/bsCf++b98+7dy5U+np6crNzY1hZMDJYasfwpYsWaJf/epX8vl8GjZsmBYvXqzCwsJYhwXEzEsvvaTRo0cfc760tFSrV6/u+oAAk5D8AQCwGeb8AQCwGZI/AAA2Q/IHAMBmSP4AANgMyR8AAJsh+QMAYDMkfwAAbIbkDwCAzZD8AQCwGZI/AAA2Q/IHAMBm/h+0grh3xa35ugAAAABJRU5ErkJggg==",
>>>>>>> e8abc172d2b691de1c1f688d38a0949f5dffc709
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp = MLP(input_size=518, hidden_size=64, output_size=1)\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(mlp.parameters())\n",
    "\n",
    "# Train the MLP on the training set\n",
    "for epoch in range(100):\n",
    "    inputs = torch.from_numpy(X_cnn_complete_train).float()\n",
    "    labels = y_cnn_complete_train.float().view(-1, 1)\n",
    "\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    preds = mlp(inputs)\n",
    "    loss = criterion(preds, labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate the performance of the model on the testing set\n",
    "with torch.no_grad():\n",
    "    inputs = torch.from_numpy(X_cnn_complete_test).float()\n",
    "    labels = y_cnn_complete_test.float().view(-1, 1)\n",
    "\n",
    "    # Forward pass\n",
    "    final_preds = mlp(inputs)\n",
    "    predicted = (final_preds > 0).float()\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_cnn_complete_test, predicted)\n",
    "    sns.heatmap(cm, linewidths=1, annot=True, fmt='g')\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = (predicted == labels).float().mean()\n",
    "    print(f\"Accuracy of MLP model: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee1153b3f7d4e5dcd3632df88b5826f13fc1401ea1edd930ba216b62830b02e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
